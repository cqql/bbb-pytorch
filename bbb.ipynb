{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load MNIST data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_transforms = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize((0.1307,), (0.3081,)),\n",
    "    torchvision.transforms.Lambda(lambda im: im.reshape(-1))\n",
    "])\n",
    "\n",
    "mnist_train = torchvision.datasets.MNIST(\n",
    "    root=\"data\", train=True, transform=mnist_transforms, download=True)\n",
    "mnist_test = mnist_train = torchvision.datasets.MNIST(\n",
    "    root=\"data\", train=False, transform=mnist_transforms, download=True)\n",
    "\n",
    "mnist_loader = torch.utils.data.DataLoader(mnist_train, batch_size=128, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(mnist_train, batch_size=1000, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the classification model\n",
    "\n",
    "This is the same model used by the author's in section 5.1 of the paper. It has two hidden layers of 1200 units each, RELU activations and softmax outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Weights(nn.Module):\n",
    "    MU = 0.0\n",
    "    SIGMA = np.log(1 + np.exp(-5.0))\n",
    "    \n",
    "    def __init__(self, n, m):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.mu = nn.Parameter(torch.zeros(n, m))\n",
    "        rho_init = torch.zeros(n, m)\n",
    "        rho_init.fill_(-5.0)\n",
    "        self.rho = nn.Parameter(rho_init)\n",
    "        \n",
    "    def sample(self):\n",
    "        epsilon = torch.randn_like(self.mu)\n",
    "        \n",
    "        return self.mu + epsilon * F.softplus(self.rho)\n",
    "    \n",
    "    def kl_divergence(self, w):\n",
    "        # Compute only the parts that influence the gradient\n",
    "        sigma = F.softplus(self.rho)\n",
    "        return 0.5 * ((w - self.MU)**2 / self.SIGMA - (w - self.mu)**2 / sigma - sigma.log()).sum()\n",
    "        \n",
    "\n",
    "class BBB(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.w1 = Weights(1200, 784)\n",
    "        self.w2 = Weights(1200, 1200)\n",
    "        self.wo = Weights(10, 1200)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        X = F.relu(F.linear(X, self.w1.sample()))\n",
    "        X = F.relu(F.linear(X, self.w2.sample()))\n",
    "        X = F.linear(X, self.wo.sample())\n",
    "        \n",
    "        return F.softmax(X, dim=-1)\n",
    "    \n",
    "    def elbo(self, X, y):\n",
    "        w1 = self.w1.sample()\n",
    "        w2 = self.w2.sample()\n",
    "        wo = self.wo.sample()\n",
    "        kld = self.w1.kl_divergence(w1) + self.w2.kl_divergence(w2) + self.wo.kl_divergence(wo)\n",
    "        \n",
    "        X = F.relu(F.linear(X, self.w1.sample()))\n",
    "        X = F.relu(F.linear(X, self.w2.sample()))\n",
    "        logits = F.linear(X, self.wo.sample())\n",
    "        \n",
    "        max, _ = logits.max(dim=-1, keepdim=True)\n",
    "        o = F.softmax(logits - max, dim=-1)\n",
    "        log_likelihood = (torch.gather(logits, -1, y.view(-1, 1)) - max - torch.log(o.sum(dim=-1))).sum()\n",
    "        \n",
    "        return kld - log_likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0: accuracy 0.11 loss 5983774.5\n",
      "Batch 10: accuracy 0.10 loss 5983862.0\n",
      "Batch 20: accuracy 0.10 loss 5983708.0\n",
      "Batch 30: accuracy 0.09 loss 5983533.5\n",
      "Batch 40: accuracy 0.10 loss 5982471.5\n",
      "Batch 50: accuracy 0.09 loss 5981312.5\n",
      "Batch 60: accuracy 0.08 loss 5979854.0\n",
      "Batch 70: accuracy 0.08 loss 5978455.5\n",
      "Batch 0: accuracy 0.11 loss 5977111.0\n",
      "Batch 10: accuracy 0.23 loss 5975173.5\n",
      "Batch 20: accuracy 0.24 loss 5973715.0\n",
      "Batch 30: accuracy 0.22 loss 5972642.5\n",
      "Batch 40: accuracy 0.37 loss 5970956.5\n",
      "Batch 50: accuracy 0.30 loss 5969783.0\n",
      "Batch 60: accuracy 0.19 loss 5968726.0\n",
      "Batch 70: accuracy 0.42 loss 5967480.0\n",
      "Batch 0: accuracy 0.47 loss 5966655.5\n",
      "Batch 10: accuracy 0.43 loss 5965555.5\n",
      "Batch 20: accuracy 0.42 loss 5964541.0\n",
      "Batch 30: accuracy 0.50 loss 5962734.5\n",
      "Batch 40: accuracy 0.43 loss 5961326.5\n",
      "Batch 50: accuracy 0.57 loss 5959913.0\n",
      "Batch 60: accuracy 0.49 loss 5958515.5\n",
      "Batch 70: accuracy 0.33 loss 5957094.5\n",
      "Batch 0: accuracy 0.43 loss 5955914.5\n",
      "Batch 10: accuracy 0.51 loss 5954269.0\n",
      "Batch 20: accuracy 0.45 loss 5952857.5\n",
      "Batch 30: accuracy 0.58 loss 5951219.0\n",
      "Batch 40: accuracy 0.42 loss 5949825.5\n",
      "Batch 50: accuracy 0.55 loss 5947423.5\n",
      "Batch 60: accuracy 0.61 loss 5946289.0\n",
      "Batch 70: accuracy 0.42 loss 5945597.5\n",
      "Batch 0: accuracy 0.42 loss 5944828.0\n",
      "Batch 10: accuracy 0.51 loss 5943608.0\n",
      "Batch 20: accuracy 0.42 loss 5943094.5\n",
      "Batch 30: accuracy 0.47 loss 5942500.5\n",
      "Batch 40: accuracy 0.54 loss 5939048.5\n",
      "Batch 50: accuracy 0.49 loss 5939243.0\n",
      "Batch 60: accuracy 0.37 loss 5939029.0\n",
      "Batch 70: accuracy 0.34 loss 5937346.0\n"
     ]
    }
   ],
   "source": [
    "bbb = BBB()\n",
    "optimizer = torch.optim.Adam(bbb.parameters(), lr=0.0001)\n",
    "\n",
    "for epoch in range(5):\n",
    "    for batch, data in enumerate(mnist_loader):\n",
    "        imgs, labels = data\n",
    "        \n",
    "        loss = bbb.elbo(imgs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch % 10 == 0:\n",
    "            imgs, labels = next(iter(test_loader))\n",
    "            classifications = bbb.forward(imgs).argmax(dim=-1)\n",
    "            accuracy = float((classifications == labels).sum()) / len(labels)\n",
    "            print(f\"Batch {batch}: accuracy {accuracy:.2f} loss {float(loss)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
